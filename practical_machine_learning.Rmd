---
title: "Practical Machine Learning project"
author: "Ahmed Zakaria"
date: "10/8/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
```
### Overview

For this project the goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. This is the "classe" variable in the training set. Then, the selected prediction model will be used to predict 20 different test cases.


### Load Data and packages

```{r, message=FALSE, warning=FALSE}
set.seed(1813)
# download the two datsets
train <-  read_csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read_csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
dim(train)
dim(test)
```


### Data partitioning

Because we want to estimate the out of sample error, we split the full dataset(train) into a training set (trainset) and a validation set (testset)

```{r, message=FALSE, warning=FALSE}
in_train  <- createDataPartition(train$classe, p=0.75, list=FALSE)
train_set <- train[ in_train, ]
test_set  <- train[-in_train, ]
dim(train_set)
dim(test_set)
```

### Data cleaning

* First we remove variables with near Zero variance (NZV)
* We then delete predictors containing missing values
* Finally we remove useless variables


```{r warning=FALSE}
nzv_var <- nearZeroVar(train_set)
train_set <- train_set[ , -nzv_var]
test_set  <- test_set [ , -nzv_var]
dim(train_set)
dim(test_set)
```

```{r}
na_var <- sapply(train_set, function(x) mean(is.na(x))) > 0.95
train_set <- train_set[ , na_var == FALSE]
test_set  <- test_set [ , na_var == FALSE]
dim(train_set)
dim(test_set)

```

We're now left with only 59 variables in each dataset
we will remove identification variables 
```{r}
train_set <- train_set[ , -(1:5)]
test_set  <- test_set [ , -(1:5)]
dim(train_set)
dim(test_set)
```


#### Correlation

We can visualize correlation among predictors left in our dataset

```{r, fig.align='center', fig.height=10}
corr_matrix <- cor(train_set[ , -54])
corrplot(corr_matrix, order = "FPC", method = "circle", type = "lower",
         tl.cex = 0.6, tl.col = rgb(0, 0, 0))
```


---

### Modeling

Here we try to fit some ML models to our data and see which one performs better. We will try:

* Decision Trees
* Random Forest
* Generalized Boosted Model

---

#### Decision Trees

```{r, fig.width=12, fig.height=12}
# fitting the model

set.seed(1813)
fit_decision_tree <- rpart(classe ~ ., data = train_set, method="class")
fancyRpartPlot(fit_decision_tree)
```



---

#### Random Forest

We now try a Random Forest model and see how it performs. We use a 3-fold cross-validation.

```{r}
set.seed(1813)
predict_decision_tree <- predict(fit_decision_tree, newdata = test_set, type="class")
class(test_set$classe)
conf_matrix_decision_tree <- confusionMatrix(predict_decision_tree, as.factor(test_set$classe))
conf_matrix_decision_tree
```

```{r}
plot(conf_matrix_decision_tree$table, col = conf_matrix_decision_tree$byClass, 
     main = paste("Decision Tree Model: Predictive Accuracy =",
                  round(conf_matrix_decision_tree$overall['Accuracy'], 4)))
```


---

#### Generalized Boosted Model

FInally we try a Generalized Boosted Model. 

```{r, message=FALSE, warning=FALSE}

set.seed(1813)
ctrl_GBM <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
fit_GBM  <- train(classe ~ ., data = train_set, method = "gbm",
                  trControl = ctrl_GBM, verbose = FALSE)

```
  
predictions based on GBM on test_set
```{r}
predict_GBM <- predict(fit_GBM, newdata = test_set)
conf_matrix_GBM <- confusionMatrix(predict_GBM, as.factor(test_set$classe))
conf_matrix_GBM
```

## Random Forest Model
```{r}
set.seed(1813)
ctrl_RF <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
fit_RF  <- train(classe ~ ., data = train_set, method = "rf",
                  trControl = ctrl_RF, verbose = FALSE)
fit_RF$finalModel
```
   
Predictions of the Random Forest model on test_set.

```{r}
predict_RF <- predict(fit_RF, newdata = test_set)
conf_matrix_RF <- confusionMatrix(predict_RF, as.factor(test_set$classe))
conf_matrix_RF
```
  
The predictive accuracy of the Random Forest model is excellent at 99.8 %
  
### 7. Applying the Best Predictive Model to the Test Data
To summarize, the predictive accuracy of the three models evaluated is as follows:  

Decision Tree Model: 74.90 %  
Generalized Boosted Model: 98.45 %  
Random Forest Model: 99.80 %  
  
The Random Forest model is selected and applied to make predictions on the 20 data points from the original testing dataset (test).
```{r}
predict_quiz <- predict(fit_RF, newdata =test)
predict_quiz

```

